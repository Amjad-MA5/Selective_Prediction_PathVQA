{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Compute risk bound and theta with Selection with Guaranteed Risk (SGR)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://arxiv.org/pdf/1705.08500 Algorithm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from risk_control import *\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Get Confidence Scores**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method1 : **Maxprob**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def max_occurence(labels):\n",
    "    count = Counter(labels)\n",
    "    max_num = max(count, key=count.get)\n",
    "    return max_num\n",
    "\n",
    "def sort(arr1, arr2 ):\n",
    "    combined = list(zip(arr1, arr2))\n",
    "\n",
    "    # Sort the combined list based on the first array's values\n",
    "    sorted_combined = sorted(combined, key=lambda x: x[0])\n",
    "\n",
    "    # Separate the sorted tuples back into two lists\n",
    "    x, y = zip(*sorted_combined)\n",
    "    return x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/teamspace/studios/this_studio/Selective_Prediction_VQA/predictions/logits_and_labels/\"\n",
    "NUM_BATCH = 2139\n",
    "residuals = []\n",
    "kappa = []\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "for batch_no in range(NUM_BATCH):\n",
    "    file_name = \"Logits_and_labels\" + str(batch_no) + \".pt\"\n",
    "    data = torch.load(data_path + file_name)\n",
    "    \n",
    "    for logits, labels in zip(data['logits'], data['labels']):\n",
    "        if(len(labels)) == 0:\n",
    "            continue\n",
    "        \n",
    "        logits = torch.from_numpy(logits)\n",
    "        prob = softmax(logits)\n",
    "        # print(prob)\n",
    "        # print(torch.max(prob).numpy())\n",
    "        kappa.append(torch.max(prob).numpy())\n",
    "        idx = torch.argmax(prob)\n",
    "        # print(prob[0][idx])\n",
    "        # print(labels)\n",
    "        residuals.append(idx.item() == max_occurence(labels))\n",
    "        # print(kappa)\n",
    "        # print(residuals)\n",
    "        # break\n",
    "    # break\n",
    "        \n",
    "    \n",
    "kappa, residuals = sort(kappa, residuals )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02 & 1.0000 & 0.0000 & 1.0000   \\\\\n",
      "0.10 & 1.0000 & 0.0000 & 1.0000   \\\\\n",
      "0.15 & 1.0000 & 0.0000 & 1.0000   \\\\\n",
      "0.20 & 1.0000 & 0.0000 & 1.0000   \\\\\n",
      "0.25 & 1.0000 & 0.0000 & 1.0000   \\\\\n",
      "1.00 & 0.7557 & 1.0000 & 0.7587   \\\\\n"
     ]
    }
   ],
   "source": [
    "kappa = np.array(kappa)\n",
    "residuals = np.array(residuals)\n",
    "risk_dict_max_prob = {}\n",
    "risk_stars = [0.02, 0.1, 0.15, 0.20, 0.25, 0.999] # desired risk\n",
    "delta = 0.01 ## confidence\n",
    "for desired_risk in risk_stars:\n",
    "    bound_cal = risk_control()\n",
    "    [theta, b_star] = bound_cal.bound(desired_risk, delta, kappa, residuals, split= False)\n",
    "    risk_dict_max_prob[str(desired_risk)] = [theta, b_star]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.02': [1.0, 1.0],\n",
       " '0.1': [1.0, 1.0],\n",
       " '0.15': [1.0, 1.0],\n",
       " '0.2': [1.0, 1.0],\n",
       " '0.25': [1.0, 1.0],\n",
       " '0.999': [0.022015542, 0.7587391736725159]}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_dict_max_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: **Vector Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/teamspace/studios/this_studio/Selective_Prediction_VQA\")\n",
    "from calibration_methods import calibrator as cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_calibrator(path, calibrator_type = \"vector_calibrator\", device = 'cpu'):\n",
    "    dict = torch.load(path)\n",
    "    if calibrator_type == \"vector_calibrator\":\n",
    "        cali = cal.VectorScaling(bias=dict['biasFlag'], \n",
    "                                 weights= dict['weights'],\n",
    "                                 num_label = dict['num_label'],\n",
    "                                 device=device,\n",
    "                                 print_verbose= False)\n",
    "        cali.temperature = dict['temperature']\n",
    "        cali.bias = dict['bias']\n",
    "    else:\n",
    "        #todo\n",
    "        return None\n",
    "    return cali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/teamspace/studios/this_studio/Selective_Prediction_VQA/calibration_methods/scaling/vector_calibrator.pt\"\n",
    "cali = load_calibrator(path, calibrator_type = \"vector_calibrator\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/teamspace/studios/this_studio/Selective_Prediction_VQA/predictions/logits_and_labels/\"\n",
    "NUM_BATCH = 2139\n",
    "residuals = []\n",
    "kappa = []\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "for batch_no in range(NUM_BATCH):\n",
    "    file_name = \"Logits_and_labels\" + str(batch_no) + \".pt\"\n",
    "    data = torch.load(data_path + file_name)\n",
    "    \n",
    "    for logits, labels in zip(data['logits'], data['labels']):\n",
    "        if(len(labels)) == 0:\n",
    "            continue\n",
    "        cali.calibrate(logits)\n",
    "        logits = torch.from_numpy(logits)\n",
    "        \n",
    "        prob = softmax(logits)\n",
    "        # print(prob)\n",
    "        # print(torch.max(prob).numpy())\n",
    "        # prob.to('cpu')\n",
    "        kappa.append(torch.max(prob).numpy())\n",
    "        idx = torch.argmax(prob)\n",
    "        # print(prob[0][idx])\n",
    "        # print(labels)\n",
    "        residuals.append(idx.item() == max_occurence(labels))\n",
    "        # print(kappa)\n",
    "        # print(residuals)\n",
    "        # break\n",
    "    # break\n",
    "        \n",
    "    \n",
    "kappa, residuals = sort(kappa, residuals )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02 & 1.0000 & 0.0000 & 1.0000   \\\\\n",
      "0.10 & 1.0000 & 0.0000 & 1.0000   \\\\\n",
      "0.15 & 1.0000 & 0.0000 & 1.0000   \\\\\n",
      "0.20 & 1.0000 & 0.0000 & 1.0000   \\\\\n",
      "0.25 & 1.0000 & 0.0000 & 1.0000   \\\\\n",
      "1.00 & 0.7557 & 1.0000 & 0.7587   \\\\\n"
     ]
    }
   ],
   "source": [
    "kappa = np.array(kappa)\n",
    "residuals = np.array(residuals)\n",
    "risk_dict_max_prob = {}\n",
    "risk_stars = [0.02, 0.1, 0.15, 0.20, 0.25, 0.999] # desired risk\n",
    "delta = 0.01 ## confidence\n",
    "for desired_risk in risk_stars:\n",
    "    bound_cal = risk_control()\n",
    "    [theta, b_star] = bound_cal.bound(desired_risk, delta, kappa, residuals, split= False)\n",
    "    risk_dict_max_prob[str(desired_risk)] = [theta, b_star]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

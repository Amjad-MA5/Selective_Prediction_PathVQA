{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Compute risk bound and theta with Selection with Guaranteed Risk (SGR)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://arxiv.org/pdf/1705.08500 Algorithm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from risk_control import *\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Get Confidence Scores**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method1 : **Maxprob**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def max_occurence(labels):\n",
    "    count = Counter(labels)\n",
    "    max_num = max(count, key=count.get)\n",
    "    return max_num\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/teamspace/studios/this_studio/Selective_Prediction_VQA/predictions/logits_and_labels/\"\n",
    "NUM_BATCH = 2139\n",
    "residuals = []\n",
    "kappa = []\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "for batch_no in range(NUM_BATCH):\n",
    "    file_name = \"Logits_and_labels\" + str(batch_no) + \".pt\"\n",
    "    data = torch.load(data_path + file_name)\n",
    "    \n",
    "    for logits, labels in zip(data['logits'], data['labels']):\n",
    "        if(len(labels)) == 0:\n",
    "            continue\n",
    "        \n",
    "        logits = torch.from_numpy(logits)\n",
    "        prob = softmax(logits)\n",
    "        # print(prob)\n",
    "        # print(torch.max(prob).numpy())\n",
    "        kappa.append(torch.max(prob).numpy())\n",
    "        idx = torch.argmax(prob)\n",
    "        # print(prob[0][idx])\n",
    "        # print(labels)\n",
    "        residuals.append(idx.item() != max_occurence(labels))\n",
    "        # print(kappa)\n",
    "        # print(residuals)\n",
    "        # break\n",
    "    # break\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02 & 0.0177 & 0.3723 & 0.0200 & 0.3773 & 0.0200  \\\\\n",
      "0.10 & 0.0964 & 0.6796 & 0.0957 & 0.6778 & 0.1000  \\\\\n",
      "0.15 & 0.1460 & 0.8077 & 0.1471 & 0.8086 & 0.1500  \\\\\n",
      "0.20 & 0.1958 & 0.9147 & 0.1945 & 0.9138 & 0.2000  \\\\\n",
      "0.25 & 0.2442 & 1.0000 & 0.2445 & 1.0000 & 0.2485  \\\\\n",
      "0.30 & 0.2429 & 1.0000 & 0.2457 & 1.0000 & 0.2472  \\\\\n",
      "1.00 & 0.2442 & 1.0000 & 0.2444 & 1.0000 & 0.2485  \\\\\n"
     ]
    }
   ],
   "source": [
    "kappa = np.array(kappa)\n",
    "residuals = np.array(residuals)\n",
    "risk_dict_max_prob = {}\n",
    "risk_stars = [0.02, 0.1, 0.15, 0.20, 0.25,0.30, 1.0] # desired risk\n",
    "delta = 0.01 ## confidence\n",
    "for desired_risk in risk_stars:\n",
    "    bound_cal = risk_control()\n",
    "    [theta, b_star] = bound_cal.bound(desired_risk, delta, kappa, residuals, split= True)\n",
    "    risk_dict_max_prob[str(desired_risk)] = [theta, b_star]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.02': [0.98898286, 0.019981025674879048],\n",
       " '0.1': [0.70664036, 0.09998997251228992],\n",
       " '0.15': [0.5008844, 0.14999056480335166],\n",
       " '0.2': [0.2773202, 0.19999532695157785],\n",
       " '0.25': [0.022015542, 0.24850052352575064],\n",
       " '0.3': [0.022936972, 0.24722394139462103],\n",
       " '1.0': [0.022015542, 0.24854849946431418]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_dict_max_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: **Vector Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/teamspace/studios/this_studio/Selective_Prediction_VQA\")\n",
    "from calibration_methods import calibrator as cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_calibrator(path, calibrator_type = \"vector_calibrator\", device = 'cpu'):\n",
    "    dict = torch.load(path)\n",
    "    if calibrator_type == \"vector_calibrator\":\n",
    "        cali = cal.VectorScaling(bias=dict['biasFlag'], \n",
    "                                 weights= dict['weights'],\n",
    "                                 num_label = dict['num_label'],\n",
    "                                 device=device,\n",
    "                                 print_verbose= False)\n",
    "        cali.temperature = dict['temperature']\n",
    "        cali.bias = dict['bias']\n",
    "    else:\n",
    "        #todo\n",
    "        return None\n",
    "    return cali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/teamspace/studios/this_studio/Selective_Prediction_VQA/calibration_methods/scaling/vector_calibrator.pt\"\n",
    "cali = load_calibrator(path, calibrator_type = \"vector_calibrator\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/teamspace/studios/this_studio/Selective_Prediction_VQA/predictions/logits_and_labels/\"\n",
    "NUM_BATCH = 2139\n",
    "residuals = []\n",
    "kappa = []\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "for batch_no in range(NUM_BATCH):\n",
    "    file_name = \"Logits_and_labels\" + str(batch_no) + \".pt\"\n",
    "    data = torch.load(data_path + file_name)\n",
    "    \n",
    "    for logits, labels in zip(data['logits'], data['labels']):\n",
    "        if(len(labels)) == 0:\n",
    "            continue\n",
    "        cali.calibrate(logits)\n",
    "        logits = torch.from_numpy(logits)\n",
    "        \n",
    "        prob = softmax(logits)\n",
    "        # print(prob)\n",
    "        # print(torch.max(prob).numpy())\n",
    "        # prob.to('cpu')\n",
    "        kappa.append(torch.max(prob).numpy())\n",
    "        idx = torch.argmax(prob)\n",
    "        # print(prob[0][idx])\n",
    "        # print(labels)\n",
    "        residuals.append(idx.item() != max_occurence(labels))\n",
    "        # print(kappa)\n",
    "        # print(residuals)\n",
    "        # break\n",
    "    # break\n",
    "        \n",
    "    \n",
    "# kappa, residuals = sort(kappa, residuals )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02 & 0.0182 & 0.3759 & 0.0193 & 0.3723 & 0.0200  \\\\\n",
      "0.10 & 0.0972 & 0.6842 & 0.0991 & 0.6852 & 0.1000  \\\\\n",
      "0.15 & 0.1469 & 0.8090 & 0.1458 & 0.8064 & 0.1500  \\\\\n",
      "0.20 & 0.1967 & 0.9190 & 0.1979 & 0.9178 & 0.2000  \\\\\n",
      "0.25 & 0.2426 & 1.0000 & 0.2460 & 1.0000 & 0.2460  \\\\\n",
      "0.30 & 0.2427 & 1.0000 & 0.2459 & 1.0000 & 0.2460  \\\\\n",
      "1.00 & 0.2436 & 1.0000 & 0.2450 & 1.0000 & 0.2470  \\\\\n"
     ]
    }
   ],
   "source": [
    "kappa = np.array(kappa)\n",
    "residuals = np.array(residuals)\n",
    "risk_dict_vec_scal = {}\n",
    "risk_stars = [0.02, 0.1, 0.15, 0.20, 0.25,0.30, 1.0] # desired risk\n",
    "delta = 0.1 ## confidence\n",
    "for desired_risk in risk_stars:\n",
    "    bound_cal = risk_control()\n",
    "    [theta, b_star] = bound_cal.bound(desired_risk, delta, kappa, residuals, split= True)\n",
    "    risk_dict_vec_scal[str(desired_risk)] = [theta, b_star]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.02': [0.9891044, 0.019991926736553832],\n",
       " '0.1': [0.6969989, 0.09999231656799441],\n",
       " '0.15': [0.50149685, 0.14999694757617216],\n",
       " '0.2': [0.26786566, 0.19999246925641007],\n",
       " '0.25': [0.022015542, 0.24597829345634653],\n",
       " '0.3': [0.022936972, 0.2460358094776587],\n",
       " '1.0': [0.022310337, 0.2469848012272543]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_dict_vec_scal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "risk_dict = {\n",
    "    'max_prob' : risk_dict_max_prob,\n",
    "    'vector_scaling_calibration' : risk_dict_vec_scal\n",
    "}\n",
    "path = \"/teamspace/studios/this_studio/Selective_Prediction_VQA/risk_bounds/\"\n",
    "torch.save(risk_dict, path + \"risk_bound.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51211"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209608"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24431796496316935"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(residuals)/residuals.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

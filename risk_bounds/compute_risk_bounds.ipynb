{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Compute risk bound and theta with Selection with Guaranteed Risk (SGR)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://arxiv.org/pdf/1705.08500 Algorithm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from risk_control import *\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Get Confidence Scores**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method1 : **Maxprob**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def max_occurence(labels):\n",
    "    count = Counter(labels)\n",
    "    max_num = max(count, key=count.get)\n",
    "    return max_num\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/teamspace/studios/this_studio/Selective_Prediction_VQA/predictions/logits_and_labels/\"\n",
    "NUM_BATCH = 2139\n",
    "residuals = []\n",
    "kappa = []\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "for batch_no in range(NUM_BATCH):\n",
    "    file_name = \"Logits_and_labels\" + str(batch_no) + \".pt\"\n",
    "    data = torch.load(data_path + file_name)\n",
    "    \n",
    "    for logits, labels in zip(data['logits'], data['labels']):\n",
    "        if(len(labels)) == 0:\n",
    "            continue\n",
    "        \n",
    "        logits = torch.from_numpy(logits)\n",
    "        prob = softmax(logits)\n",
    "        # print(prob)\n",
    "        # print(torch.max(prob).numpy())\n",
    "        kappa.append(torch.max(prob).numpy())\n",
    "        idx = torch.argmax(prob)\n",
    "        # print(prob[0][idx])\n",
    "        # print(labels)\n",
    "        residuals.append(idx.item() != max_occurence(labels))\n",
    "        # print(kappa)\n",
    "        # print(residuals)\n",
    "        # break\n",
    "    # break\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02 & 0.0177 & 0.3726 & 0.0193 & 0.3717 & 0.0200  \\\\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10 & 0.0964 & 0.6780 & 0.0969 & 0.6826 & 0.1000  \\\\\n",
      "0.15 & 0.1460 & 0.8065 & 0.1451 & 0.8045 & 0.1500  \\\\\n",
      "0.20 & 0.1958 & 0.9168 & 0.1968 & 0.9161 & 0.2000  \\\\\n",
      "0.25 & 0.2446 & 1.0000 & 0.2440 & 1.0000 & 0.2489  \\\\\n",
      "0.30 & 0.2434 & 1.0000 & 0.2452 & 1.0000 & 0.2478  \\\\\n",
      "1.00 & 0.2439 & 1.0000 & 0.2447 & 0.9999 & 0.2482  \\\\\n"
     ]
    }
   ],
   "source": [
    "kappa = np.array(kappa)\n",
    "residuals = np.array(residuals)\n",
    "risk_dict_max_prob = {}\n",
    "risk_stars = [0.02, 0.1, 0.15, 0.20, 0.25,0.30, 1.0] # desired risk\n",
    "delta = 0.01 ## confidence\n",
    "for desired_risk in risk_stars:\n",
    "    bound_cal = risk_control()\n",
    "    [theta, b_star] = bound_cal.bound(desired_risk, delta, kappa, residuals, split= True)\n",
    "    risk_dict_max_prob[str(desired_risk)] = [theta, b_star]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.02': [0.9894505, 0.0199641253168461],\n",
       " '0.1': [0.70405567, 0.09997844312894971],\n",
       " '0.15': [0.5049889, 0.14999522941302407],\n",
       " '0.2': [0.27237254, 0.19999602656843307],\n",
       " '0.25': [0.022311127, 0.24889408630636511],\n",
       " '0.3': [0.02225437, 0.2477710283302041],\n",
       " '1.0': [0.02400235, 0.2482029990738233]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_dict_max_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: **Vector Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/teamspace/studios/this_studio/Selective_Prediction_VQA\")\n",
    "from calibration_methods import calibrator as cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_calibrator(path, calibrator_type = \"vector_calibrator\", device = 'cpu'):\n",
    "    dict = torch.load(path)\n",
    "    if calibrator_type == \"vector_calibrator\":\n",
    "        cali = cal.VectorScaling(bias=dict['biasFlag'], \n",
    "                                 weights= dict['weights'],\n",
    "                                 num_label = dict['num_label'],\n",
    "                                 device=device,\n",
    "                                 print_verbose= False)\n",
    "        cali.temperature = dict['temperature']\n",
    "        cali.bias = dict['bias']\n",
    "    else:\n",
    "        #todo\n",
    "        return None\n",
    "    return cali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/teamspace/studios/this_studio/Selective_Prediction_VQA/calibration_methods/scaling/vector_calibrator.pt\"\n",
    "cali = load_calibrator(path, calibrator_type = \"vector_calibrator\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/teamspace/studios/this_studio/Selective_Prediction_VQA/predictions/logits_and_labels/\"\n",
    "NUM_BATCH = 2139\n",
    "residuals = []\n",
    "kappa = []\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "for batch_no in range(NUM_BATCH):\n",
    "    file_name = \"Logits_and_labels\" + str(batch_no) + \".pt\"\n",
    "    data = torch.load(data_path + file_name)\n",
    "    \n",
    "    for logits, labels in zip(data['logits'], data['labels']):\n",
    "        if(len(labels)) == 0:\n",
    "            continue\n",
    "        logits = cali.calibrate(logits)\n",
    "        logits = torch.from_numpy(logits)\n",
    "        \n",
    "        prob = softmax(logits)\n",
    "        # print(prob)\n",
    "        # print(torch.max(prob).numpy())\n",
    "        # prob.to('cpu')\n",
    "        kappa.append(torch.max(prob).numpy())\n",
    "        idx = torch.argmax(prob)\n",
    "        # print(prob[0][idx])\n",
    "        # print(labels)\n",
    "        residuals.append(idx.item() != max_occurence(labels))\n",
    "        # print(kappa)\n",
    "        # print(residuals)\n",
    "        # break\n",
    "    # break\n",
    "        \n",
    "    \n",
    "# kappa, residuals = sort(kappa, residuals )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02 & 0.0000 & 0.0000 & 0.0306 & 0.4583 & 0.9941  \\\\\n",
      "0.10 & 0.0972 & 0.6783 & 0.0946 & 0.6797 & 0.1000  \\\\\n",
      "0.15 & 0.1469 & 0.7966 & 0.1475 & 0.7967 & 0.1500  \\\\\n",
      "0.20 & 0.1967 & 0.9008 & 0.1957 & 0.9023 & 0.2000  \\\\\n",
      "0.25 & 0.2451 & 1.0000 & 0.2448 & 1.0000 & 0.2484  \\\\\n",
      "0.30 & 0.2445 & 1.0000 & 0.2453 & 1.0000 & 0.2479  \\\\\n",
      "1.00 & 0.2459 & 1.0000 & 0.2439 & 1.0000 & 0.2492  \\\\\n"
     ]
    }
   ],
   "source": [
    "kappa = np.array(kappa)\n",
    "residuals = np.array(residuals)\n",
    "risk_dict_vec_scal = {}\n",
    "risk_stars = [0.02, 0.1, 0.15, 0.20, 0.25,0.30, 1.0] # desired risk\n",
    "delta = 0.1 ## confidence\n",
    "for desired_risk in risk_stars:\n",
    "    bound_cal = risk_control()\n",
    "    [theta, b_star] = bound_cal.bound(desired_risk, delta, kappa, residuals, split= True)\n",
    "    risk_dict_vec_scal[str(desired_risk)] = [theta, b_star]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.02': [1.0, 0.9941177368164062],\n",
       " '0.1': [0.99844825, 0.0999940050639865],\n",
       " '0.15': [0.96077937, 0.14999492921580543],\n",
       " '0.2': [0.75928205, 0.19999539489987525],\n",
       " '0.25': [0.14571935, 0.2484226213998834],\n",
       " '0.3': [0.14843729, 0.24787624694690857],\n",
       " '1.0': [0.15131189, 0.2492277806559775]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_dict_vec_scal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "risk_dict = {\n",
    "    'max_prob' : risk_dict_max_prob,\n",
    "    'vector_scaling_calibration' : risk_dict_vec_scal\n",
    "}\n",
    "path = \"/teamspace/studios/this_studio/Selective_Prediction_VQA/risk_bounds/\"\n",
    "torch.save(risk_dict, path + \"risk_bound.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51335"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209608"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24490954543719706"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(residuals)/residuals.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
